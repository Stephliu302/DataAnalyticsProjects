{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EtlhRX9ZxC-u"
      },
      "source": [
        "# Example 1: Simple MNIST CNN Model\n",
        "\n",
        "GSB 545: Final Project\n",
        "\n",
        "Stephanie Liu\n",
        "\n",
        "June 7, 2022\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jrZgv1uYwycY"
      },
      "source": [
        "# Simple MNIST convnet (Convolutional Neural Network)\n",
        "\n",
        "See below for more information on the **original example** this was based on.\n",
        "\n",
        "**Author:** [fchollet](https://twitter.com/fchollet)<br>\n",
        "**Date created:** 2015/06/19<br>\n",
        "**Last modified:** 2020/04/21<br>\n",
        "**Description:** A simple convnet that achieves ~99% test accuracy on MNIST."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cs3TdtvTIP9r"
      },
      "source": [
        "Resources Referenced in this Example:\n",
        "\n",
        "- Neural Networks: https://sanchit2843.medium.com/introduction-to-neural-networks-660f6909fba9\n",
        "\n",
        "- CNN: https://towardsdatascience.com/a-comprehensive-guide-to-convolutional-neural-networks-the-eli5-way-3bd2b1164a53\n",
        "\n",
        "- MNIST Dataset: http://yann.lecun.com/exdb/mnist/\n",
        "\n",
        "- Example: https://keras.io/examples/vision/mnist_convnet/\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fRDpho8MQVff"
      },
      "source": [
        "## Introduction\n",
        "\n",
        "This example walks through how to classify images (of numbers) in the MNIST dataset to a digit between 0 and 9. The example uses a Convolutional Neural Network for classification, and shows how to do so in python using the keras package."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JZEMNMXyxl8t"
      },
      "source": [
        "### **Overview of Neural Networks**\n",
        "\n",
        "A neural network is the basic building block of deep learning, based on aspects of the human brain. It consists of layers stacked together to form a larger architecture. It consists of 3 types of layers, and within each layer, there are neurons, or nodes, that each have their own weight. \n",
        "\n",
        "- *Input layer*: This takes the independent variables from the data as input (each node is one variable)\n",
        "- *Hidden layer(s*): This is the middle section of the model. There can be multiple hidden layers, and within each layer you can specify the number of nodes in each.\n",
        "- *Output layer*: This is the layer that produces the predicted target variable. In our example, it would produce the predicted class (digit between 0-9) that the observation is assigned to.\n",
        "\n",
        "Neural Networks are the weighted sum of inputs, that is the sum of each weighted node throughout the model. Keep in mind that in general, Simple Neural Networks take a series of inputs for one observation within the data, pass them through the nodes of each layer of the model, and produce a predicted output for that observation. The model then continues to do this for every observation of the data.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RrvGfwgJQP0K"
      },
      "source": [
        "\n",
        "### **Convolutional Neural Networks**\n",
        "\n",
        "Convolutional Neural Networks (CNN) is a class of artificial neural network (ANN), that is commonly applied to analyze visual imagery. It is a Deep Learning algorithm which can take in an input image, assign importance (i.e. updatable weights) to various objects in the image and be able to differentiate one from the other. \n",
        "\n",
        "\n",
        "An image is a matrix of pixel values. For instance, an image could be saved as a 3x3 matrix of pixels, and this is how it is stored in the data. The CNN model is able to capture the *Spatial* and *Temporal* dependencies in an image. The network can be trained to better understand the sophistication of the image by applying the relevant filters. The role of the CNN is to reduce the images into an easy-to-process form, without losing features which are essential to getting a good prediction.\n",
        "\n",
        "\n",
        "**Convolution Layer:**\n",
        "The element involved in carrying out the *convolution operation* in the first part of a Convolutional Layer is called the **Kernel/Filter, K**. This is typically a smaller subset (in size) of the of the original image. For example, for an image of size 5x5x1, we could choose a 3x3x1 kernel. When **Stride Length = 1** (Non-Strided), the kernel shifts 9 times, every time performing a matrix multiplication operation between K and the portion P of the image over which the kernel is hovering. The filter moves with a certain Stride Value, repeating the process until the entire image is traversed.\n",
        "\n",
        "\n",
        "There are two types of results to the convolution operation, one in which the convolved feature has smaller dimensionality than the input (**Valid Padding)**, and the other in which the dimensionality is either increased or remains the same (**Same Padding**).\n",
        "\n",
        "**Pooling Layer(s):**\n",
        "\n",
        "Similar to the Convolutional Layer, the **Pooling layer** helps reduce the spatial size of the *Convolved Feature*. This is to decrease the computational power required to process the data. It is useful for extracting important features which do not vary from a rotational and positional standpoint. \n",
        "\n",
        "There are two types of Pooling: \n",
        "- **Max Pooling**: returns the *maximum value* from the portion of the image covered by the Kernel.\n",
        "- **Average Pooling**: returns the *average* of all the values from the portion of the image covered by the Kernel.\n",
        "\n",
        "Usually, Max Pooling is preferred (and we'll use this approach in teh exmaple below).\n",
        "\n",
        "Finally, after going through the two layers described above, we flatten the final output and feed it to a regular Neural Network for classification output.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zIhwNe7sadAR"
      },
      "source": [
        "### **About the MNIST Dataset**\n",
        "\n",
        "The MNIST dataset is a database of handwritten digits. It has a training set of 60,000 examples, and a test set of 10,000 examples. It is a subset of a larger set available from NIST. The digits have been normalized and centered in a fixed-size image. These images have been saved as a matrix of pixels, which is what we will feed into the model below."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BKT5dNRiwycc"
      },
      "source": [
        "## Setup\n",
        "\n",
        "Our first step will be to load in the required packages used for the following model. This example walkthrough uses the *keras* package (similar to how tidymodels works in RStudio), which is a package in *tensorflow* that is typically used for Neural Networks. We'll also import *numpy*, which is a package in python that is used for many basic computations (and randomization)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "92Z0wR8cwycd"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z0bdtVnkwyce"
      },
      "source": [
        "## Prepare the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZmmR5s_nF5Zy"
      },
      "source": [
        "\n",
        "Loading in the MNIST Data Returns:\n",
        "  Tuple of NumPy arrays: (x_train, y_train), (x_test, y_test).\n",
        "\n",
        "**x_train**: uint8 NumPy array of grayscale image data with shapes\n",
        "  (60000, 28, 28), containing the training data. Pixel values range\n",
        "from 0 to 255.\n",
        "\n",
        "**y_train**: uint8 NumPy array of digit labels (integers in range 0-9)\n",
        "  with shape (60000,) for the training data.\n",
        "\n",
        "**x_test**: uint8 NumPy array of grayscale image data with shapes\n",
        "  (10000, 28, 28), containing the test data. Pixel values range\n",
        "from 0 to 255.\n",
        "\n",
        "**y_test**: uint8 NumPy array of digit labels (integers in range 0-9)\n",
        "  with shape (10000,) for the test data.\n",
        "\n",
        "\n",
        "Since the pixel values range from 0 to 255, we scale these values to get values between 0 and 1 by dividing the values by 255. \n",
        "\n",
        "The target (y) values range from 0 to 9, to represent one of the ten possible numbers displayed in the image.\n",
        "\n",
        "Note that **x_train** and **y_train** have 60000 observations, while the **x_test** and **y_test** have 10000 observations. This indicates about an 85-15% train-test split.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_xWdS5RYwycf",
        "outputId": "396c5e05-6849-4817-e278-76ff3910f5df"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n",
            "x_train shape: (60000, 28, 28, 1)\n",
            "60000 train samples\n",
            "10000 test samples\n"
          ]
        }
      ],
      "source": [
        "# Model / data parameters\n",
        "num_classes = 10\n",
        "input_shape = (28, 28, 1)\n",
        "\n",
        "# load mnist data, split between train and test sets\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
        "\n",
        "# Scale images to [0, 1] range\n",
        "x_train = x_train.astype(\"float32\") / 255\n",
        "x_test = x_test.astype(\"float32\") / 255\n",
        "# Make sure images have shape (28, 28, 1)\n",
        "x_train = np.expand_dims(x_train, -1)\n",
        "x_test = np.expand_dims(x_test, -1)\n",
        "print(\"x_train shape:\", x_train.shape)\n",
        "print(x_train.shape[0], \"train samples\")\n",
        "print(x_test.shape[0], \"test samples\")\n",
        "\n",
        "\n",
        "# convert class vectors to binary class matrices (with 0 or 1)\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZJ5ZCFJSwycf"
      },
      "source": [
        "## Build the model\n",
        "\n",
        "Next, we will build the structure of the CNN model. Note that we will not fit/train the data on the model until a later step. \n",
        "\n",
        "The model below has the following layers:\n",
        "- *Input layer*: with shape (28, 28, 1)\n",
        "- *Convolutional layer*: with 32 filter, a 3x3 kernel, and relu activation function\n",
        "- *Pooling layer* (MaxPooling): with a 2x2 pool size\n",
        "\n",
        "- Second *Convolutional layer*: with 64 filter, a 3x3 kernal, and relu activation function\n",
        "- Second *Pooling layer* (MaxPooling): with a 2x2 pool size\n",
        "- *Flatten + Dropout layers*: to flatten the matrices before passing to output layer; also to change some inputs to 0's at a given frequency (0.5)\n",
        "- *Dense layer* (Output): which outputs 10 classes and uses the softmax activation function\n",
        "\n",
        "You can see a summary of the model structure in the code output below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YifAM-hqwycg",
        "outputId": "f062e354-8708-49f3-b721-211dc366465e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 26, 26, 32)        320       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 13, 13, 32)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 11, 11, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 5, 5, 64)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 1600)              0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 1600)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 10)                16010     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 34,826\n",
            "Trainable params: 34,826\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model = keras.Sequential(\n",
        "    [\n",
        "        keras.Input(shape=input_shape),\n",
        "        layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n",
        "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "        layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
        "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "        layers.Flatten(),\n",
        "        layers.Dropout(0.5),\n",
        "        layers.Dense(num_classes, activation=\"softmax\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o8zyCzOIwych"
      },
      "source": [
        "## Train the model\n",
        "\n",
        "Now that we've built the model, we can train the model on the training MNIST data.\n",
        "Before doing so, we will use the ***compile*** function to specify the *loss function* (categorical crossentropy), *optimizer* (adam), and preferred *metrics* (accuracy).\n",
        "\n",
        "- *categorical crossentropy loss function*: Computes the crossentropy loss between the labels and predictions. Use this crossentropy loss function when there are two or more label classes (in our case we have 10 classes, digits 0-9).\n",
        "\n",
        "- *adam optimizer*: Optimizer that implements the Adam algorithm. Adam optimization is a stochastic gradient descent method that is based on adaptive estimation of first-order and second-order moments.\n",
        "\n",
        "- *accuracy metric*: Calculates how often predictions equal labels. Commonly used for classification models, to help determine model performance.\n",
        "\n",
        "Next, we use the ***fit*** function to fit the model on the train x and y data. Here, we specify the following:\n",
        "\n",
        "- *batch size = 128*\n",
        "\n",
        "    Number of samples per gradient update.\n",
        "\n",
        "- *epochs = 15*\n",
        "\n",
        "    Number of epochs to train the model. An epoch is an iteration over the entire x and y data provided.\n",
        "\n",
        "- *validation split = 0.1*\n",
        "\n",
        "    Float between 0 and 1. Fraction of the training data to be used as validation data. The model will set apart this fraction of the training data, will not train on it, and will evaluate the loss and any model metrics on this data at the end of each epoch. The validation data is selected from the last samples in the x and y data provided, before shuffling.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jeiDZ0R6wych",
        "outputId": "91b6ef36-e0a2-40fe-80e1-1d8e658d7501"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "422/422 [==============================] - 45s 103ms/step - loss: 0.3596 - accuracy: 0.8925 - val_loss: 0.0851 - val_accuracy: 0.9775\n",
            "Epoch 2/15\n",
            "422/422 [==============================] - 42s 100ms/step - loss: 0.1108 - accuracy: 0.9661 - val_loss: 0.0586 - val_accuracy: 0.9842\n",
            "Epoch 3/15\n",
            "422/422 [==============================] - 43s 101ms/step - loss: 0.0861 - accuracy: 0.9732 - val_loss: 0.0468 - val_accuracy: 0.9880\n",
            "Epoch 4/15\n",
            "422/422 [==============================] - 42s 100ms/step - loss: 0.0733 - accuracy: 0.9781 - val_loss: 0.0416 - val_accuracy: 0.9888\n",
            "Epoch 5/15\n",
            "422/422 [==============================] - 42s 100ms/step - loss: 0.0625 - accuracy: 0.9811 - val_loss: 0.0396 - val_accuracy: 0.9878\n",
            "Epoch 6/15\n",
            "422/422 [==============================] - 43s 101ms/step - loss: 0.0568 - accuracy: 0.9829 - val_loss: 0.0378 - val_accuracy: 0.9913\n",
            "Epoch 7/15\n",
            "422/422 [==============================] - 44s 104ms/step - loss: 0.0519 - accuracy: 0.9838 - val_loss: 0.0348 - val_accuracy: 0.9898\n",
            "Epoch 8/15\n",
            "422/422 [==============================] - 42s 101ms/step - loss: 0.0487 - accuracy: 0.9849 - val_loss: 0.0334 - val_accuracy: 0.9908\n",
            "Epoch 9/15\n",
            "422/422 [==============================] - 42s 101ms/step - loss: 0.0458 - accuracy: 0.9854 - val_loss: 0.0337 - val_accuracy: 0.9907\n",
            "Epoch 10/15\n",
            "422/422 [==============================] - 43s 102ms/step - loss: 0.0419 - accuracy: 0.9869 - val_loss: 0.0343 - val_accuracy: 0.9907\n",
            "Epoch 11/15\n",
            "422/422 [==============================] - 42s 100ms/step - loss: 0.0404 - accuracy: 0.9873 - val_loss: 0.0316 - val_accuracy: 0.9917\n",
            "Epoch 12/15\n",
            "422/422 [==============================] - 43s 101ms/step - loss: 0.0391 - accuracy: 0.9875 - val_loss: 0.0299 - val_accuracy: 0.9917\n",
            "Epoch 13/15\n",
            "422/422 [==============================] - 43s 103ms/step - loss: 0.0365 - accuracy: 0.9880 - val_loss: 0.0306 - val_accuracy: 0.9912\n",
            "Epoch 14/15\n",
            "422/422 [==============================] - 42s 100ms/step - loss: 0.0344 - accuracy: 0.9881 - val_loss: 0.0288 - val_accuracy: 0.9923\n",
            "Epoch 15/15\n",
            "422/422 [==============================] - 42s 101ms/step - loss: 0.0336 - accuracy: 0.9893 - val_loss: 0.0290 - val_accuracy: 0.9923\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fd20578be50>"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "batch_size = 128\n",
        "epochs = 15\n",
        "\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "\n",
        "model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kj95nu12wyci"
      },
      "source": [
        "## Evaluate the trained model\n",
        "\n",
        "Now that we've trained the model on the data, we can use the ***evaluate*** function to see how well the model perfoms (i.e. how well it correctly classifies the images to its corresponding digit). Note here that we fit the model above on the train data, and we will evaluate here on the test data. We will print the test loss and accuracy, and use these metrics to help us determine if this is a good model or not.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0kaSjMtiwyci",
        "outputId": "f6b2dfd2-ff1e-4fd3-900a-2ebce03ee4ea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test loss: 0.024533724412322044\n",
            "Test accuracy: 0.9914000034332275\n"
          ]
        }
      ],
      "source": [
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print(\"Test loss:\", score[0])\n",
        "print(\"Test accuracy:\", score[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iFJDgyuLl3v0"
      },
      "source": [
        "We see that the model predicted (classified) the images with over **99% accuracy**. This is really good, and suggests that this model is good to use to classify the MNIST images to their corresponding digits. "
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Example 1: MNIST Convolutional Neural Network",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
